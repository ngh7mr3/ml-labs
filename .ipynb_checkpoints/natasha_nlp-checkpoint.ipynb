{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "humanitarian-progress",
   "metadata": {},
   "source": [
    "# NLP tasks example with `Natasha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "outdoor-charter",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indian-latex",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "every-college",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://nplus1.ru/news/2018/10/16/asymptotically-safe\n",
    "# complexity 9.7\n",
    "text_sm = '''\n",
    "\n",
    "Асимптотическая безопасность квантовой гравитации связала заряды и массы тяжелых кварков\n",
    "\n",
    "Matt Cummings / flickr.com\n",
    "\n",
    "Физики-теоретики из Германии использовали теорию асимптотически безопасной квантовой гравитации, чтобы рассчитать отношение масс двух самых тяжелых кварков — t-кварка и b-кварка. Для этого ученые отталкивались от известных значений абелева гиперзаряда и констант электрослабой и сильной связи и прослеживали поток ренормализационной группы вплоть до планковских масштабов энергии. Кроме того, исследователи показали, что отношения зарядов и масс кварков связаны между собой. Статья опубликована в Physical Review Letters и находится в свободном доступе.\n",
    "\n",
    "Одно из важнейших свойств Стандартной модели — это перенормируемость, то есть возможность избавляться от бесконечно расходящихся величин. Чтобы понять, в чем заключается идея перенормировок, сначала надо понять, откуда в теории берутся расходимости. Основным объектом Стандартной модели, как и любой квантовой теории поля, являются пропагаторы — функции, которые показывают вероятность перехода между различными конфигурациями квантовых полей. Например, вероятность частицы переместиться между двумя заданными точками за фиксированный промежуток времени. Для свободных теорий, в которых частицы не взаимодействуют друг с другом, найти пропагаторы очень легко — достаточно выписать и решить уравнения теории. Если же добавить в теорию взаимодействие, которое «перемешивает» поля — например, электромагнитное поле и поле электронов, — уравнения резко усложняются, и точно решить их становится невозможно. Чтобы справиться с этой проблемой, физики считают, что поля свободных теорий слабо «цепляются» друг за друга, а затем вычисляют поправки к пропагаторам свободной теории; чем более высокие порядки учитываются, тем точнее получается результат. Наглядно такое вычисление можно представить в виде диаграмм Фейнмана. При низких энергиях этот подход очень хорошо работает — в частности, теоретическое значение магнитного момента электрона совпадает с экспериментом с точностью порядка 10−12.\n",
    "\n",
    "Свободные пропагаторы в квантовой электродинамике (рисунок 2), вершина, описывающая взаимодействие электрона и фотона (рисунок 1) и процесс рассеяния фотона на электроне в древесном приближении (рисунок 3)\n",
    "\n",
    "Wikimedia Commons\n",
    "Поделиться\n",
    "\n",
    "Петлевые поправки к процессу рассеяния фотона на электроне (рисунок 3 с предыдущей картинки)\n",
    "\n",
    "Wikimedia Commons\n",
    "Поделиться\n",
    "\n",
    "1/2\n",
    "\n",
    "К сожалению, при больших энергиях (то есть на маленьких расстояниях) поправки к пропагаторам бесконечно растут, что противоречит экспериментальным данным. Чтобы убрать эти расходимости, физики определенным образом «подкручивают» напряженности полей и постоянных теории, которые входили в исходные уравнения движения, заставляя их зависеть от масштаба энергий. Другими словами, в результате этой процедуры ученые выделяют в пропагаторах физически осмысленные вклады и добавляют в исходный лагранжиан теории специально подобранные контрчлены, которые сокращают «нефизичные» расходимости. В этом заключается смысл процедуры перенормировки. Если число контрчленов конечно, то теория «хорошая», и с ее помощью можно рассчитать значения наблюдаемых величин. Стандратная модель относится именно к такому типу теорий. Если же расходимости можно убрать только с помощью бесконечного числа контрчленов, то предсказательная сила теории равна нулю, поскольку она требует вводить бесконечное число свободных параметров. Это случай квантовой гравитации. Физики пытались решить эту проблему, разработав принципиально новые экзотические теории — например, теорию струн или теорию петлевой квантовой гравитации. Тем не менее, до сих пор не существует экспериментов, которые подтвердили бы эти теории.\n",
    "\n",
    "С другой стороны, в конце 1970-х годов Стивен Вайнберг заметил, что неперенормируемость теории квантовой гравитации не обязательно означает, что с ее помощью нельзя рассчитывать значения наблюдаемых величин. Вместо того чтобы бороться с расходимостями, возникающими в стандартных методах, Вайнберг предложил «зайти» с противоположного конца — описать теорию с помощью конечного числа конечных параметров на больших энергиях, а потом продолжить зависимости в область низких энергий. Такое свойство теории Вайнберг назвал асимптотической безопасностью по аналогии с асимптотической свободой Квантовой хромодинамики, в которой константа связи стремится к нулю на больших энергиях. Математический инструмент, который позволяет выполнить такие расчеты, предложили в начале 1990-х годов Кристоф Веттерих (Christof Wetterich) и Мартин Рейтер (Martin Reuter). В 2009 году Михаил Шапошников и Кристов Веттерих рассчитали с помощью теории асимптотически безопасной гравитации предполагаемую массу бозона Хиггса, которая составила примерно 126 гигаэлектронвольт, что практически в точности совпадает с результатами последовавших измерений на Большом адронном коллайдере. Кроме того, теория с асимптотической безопасностью практически не нужно вводить новые частицы, как это предлагает делать большинство альтернативных теорий вроде теории струн. Это делает идею асимптотической безопасности очень привлекательной для теоретиков.\n",
    "\n",
    "В новой статье физики Астрид Эйххорн (Astrid Eichhorn) и Аарон Хельд (Aaron Held) использовали асимптотически безопасную гравитацию, чтобы объяснить огромный разрыв масс между двумя самыми массивными кварками — t-кварком (mt ≈ 173 гигаэлектронвольт) и b-кварком (mb ≈ 4,9 гигаэлектронвольт). В Стандартной модели массы кварков возникают из-за того, что частицы «цепляются» за поле Хиггса, равномерно заполняющего Вселенную (подробнее про этот эффект можно прочитать в материале «С днем рождения, БАК!»). Сила, с которой кварки «цепляются» к полю, определяется юкавскими константами связи yb и yt, значения которых невозможно рассчитать в рамках Стандартной модели. С другой стороны, эти константы должны быть связаны с абелевым гиперзарядом соотношением yt2 — yb2 = ⅓gy2, которое выполняется для очень больших энергий (много больше планковского масштаба). В то же время, абелев гиперзаряд связан с параметрами квантовой гравитации. Используя экспериментально измеренное значение этого заряда, вычисляя бета-функцию в однопетлевом приближении и прослеживая поток ренормализационной группы до планковских масштабов энергий, физики рассчитали значение одного из этих параметров. Значение второго параметра ученые зафиксировали исходя из массы b-кварка. Наконец, исследователи рассчитали массу t-кварка, используя найденные значения параметров, и получили величину около mt ≈ 178 гигаэлектронвольт, что хорошо согласуется с экспериментом.\n",
    "\n",
    "Зависимости параметров Стандартной модели от масштаба энергий, рассчитанные учеными в рамках асимптотически безопасной теории квантовой гравитации\n",
    "\n",
    "A. Eichhorn & A. Held / Physical Review Letters\n",
    "Поделиться\n",
    "\n",
    "\n",
    "Кроме того, из расчетов физиков следует еще три интересных замечания. Во-первых, постоянные квантовой гравитации для абелевых и неабелевых полей должны быть очень близки — это согласуется с тем, что гравитационные поля одинаково сильно взаимодействуют с частицами разной природы, если они имеют одинаковую массу. Во-вторых, характерный масштаб энергий, на которых гравитационные вклады «выключаются», совпадает с планковской энергией. В-третьих, заряды t-кварка и b-кварка должны относиться как Qt/Qb = −2. Если бы хотя бы одно из этих трех предположений не выполнялось, отношение масс кварков получились бы совершенно другим — исправить расхождение не помогло бы даже изменение параметров квантовой гравитации.\n",
    "\n",
    "Несмотря на то, что эффекты квантовой гравитации должны очень слабо проявляться на наблюдаемых масштабах энергии, физики все равно пытаются их обнаружить, измеряя тонкие эффекты с высокой точностью. Например, отслеживают расстояние до Луны и колебания приливных сил, перепроверяют классические предсказания ОТО и сравнивают временну́ю задержку между фотонами, приходящими от далеких гамма-всплесков. Как и ожидалось, ни один из этих экспериментов не нашел отклонений от Стандартной модели или ОТО.\n",
    "\n",
    "Дмитрий Трунин\n",
    "'''\n",
    "doc_sm = Doc(text_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-student",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "identical-toddler",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Асимптотическая',\n",
       " 'безопасность',\n",
       " 'квантовой',\n",
       " 'гравитации',\n",
       " 'связала',\n",
       " 'заряды',\n",
       " 'и',\n",
       " 'массы',\n",
       " 'тяжелых',\n",
       " 'кварков']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sm.segment(seg)\n",
    "list(map(lambda x: x.text,doc_sm.tokens[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intended-cornwall",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Асимптотическая безопасность квантовой гравитации связала заряды и массы тяжелых кварков\\n\\nMatt Cummings / flickr.com\\n\\nФизики-теоретики из Германии использовали теорию асимптотически безопасной квантовой гравитации, чтобы рассчитать отношение масс двух самых тяжелых кварков — t-кварка и b-кварка.',\n",
       " 'Для этого ученые отталкивались от известных значений абелева гиперзаряда и констант электрослабой и сильной связи и прослеживали поток ренормализационной группы вплоть до планковских масштабов энергии.',\n",
       " 'Кроме того, исследователи показали, что отношения зарядов и масс кварков связаны между собой.',\n",
       " 'Статья опубликована в Physical Review Letters и находится в свободном доступе.',\n",
       " 'Одно из важнейших свойств Стандартной модели — это перенормируемость, то есть возможность избавляться от бесконечно расходящихся величин.',\n",
       " 'Чтобы понять, в чем заключается идея перенормировок, сначала надо понять, откуда в теории берутся расходимости.',\n",
       " 'Основным объектом Стандартной модели, как и любой квантовой теории поля, являются пропагаторы — функции, которые показывают вероятность перехода между различными конфигурациями квантовых полей.',\n",
       " 'Например, вероятность частицы переместиться между двумя заданными точками за фиксированный промежуток времени.',\n",
       " 'Для свободных теорий, в которых частицы не взаимодействуют друг с другом, найти пропагаторы очень легко — достаточно выписать и решить уравнения теории.',\n",
       " 'Если же добавить в теорию взаимодействие, которое «перемешивает» поля — например, электромагнитное поле и поле электронов, — уравнения резко усложняются, и точно решить их становится невозможно.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.text,doc_sm.sents[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-float",
   "metadata": {},
   "source": [
    "### Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mature-inclusion",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocToken(start=2, stop=17, text='Асимптотическая', pos='ADJ', feats=<Acc,Pos,Fem,Sing>),\n",
       " DocToken(start=18, stop=30, text='безопасность', pos='NOUN', feats=<Inan,Acc,Fem,Sing>),\n",
       " DocToken(start=31, stop=40, text='квантовой', pos='ADJ', feats=<Gen,Pos,Fem,Sing>),\n",
       " DocToken(start=41, stop=51, text='гравитации', pos='NOUN', feats=<Inan,Gen,Fem,Sing>),\n",
       " DocToken(start=52, stop=59, text='связала', pos='VERB', feats=<Perf,Fem,Ind,Sing,Past,Fin,Act>),\n",
       " DocToken(start=60, stop=66, text='заряды', pos='NOUN', feats=<Inan,Acc,Masc,Plur>),\n",
       " DocToken(start=67, stop=68, text='и', pos='CCONJ'),\n",
       " DocToken(start=69, stop=74, text='массы', pos='NOUN', feats=<Inan,Acc,Fem,Plur>),\n",
       " DocToken(start=75, stop=82, text='тяжелых', pos='ADJ', feats=<Gen,Pos,Plur>),\n",
       " DocToken(start=83, stop=90, text='кварков', pos='NOUN', feats=<Inan,Gen,Masc,Plur>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sm.tag_morph(morph_tagger)\n",
    "doc_sm.tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greatest-incident",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Асимптотическая ADJ|Case=Acc|Degree=Pos|Gender=Fem|Number=Sing\n",
      "        безопасность NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
      "           квантовой ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "          гравитации NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "             связала VERB|Aspect=Perf|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
      "              заряды NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
      "                   и CCONJ\n",
      "               массы NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur\n",
      "             тяжелых ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
      "             кварков NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur\n",
      "                Matt X|Foreign=Yes\n",
      "            Cummings X|Foreign=Yes\n",
      "                   / PUNCT\n",
      "              flickr X|Foreign=Yes\n",
      "                   . PUNCT\n",
      "                 com X|Foreign=Yes\n",
      "    Физики-теоретики PUNCT\n",
      "                  из ADP\n",
      "            Германии PROPN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "        использовали VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
      "              теорию NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
      "      асимптотически NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "          безопасной ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "           квантовой ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "          гравитации NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "                   , PUNCT\n",
      "               чтобы SCONJ\n",
      "          рассчитать VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
      "           отношение NOUN|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
      "                масс NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
      "                двух NUM|Case=Gen\n",
      "               самых ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
      "             тяжелых ADJ|Case=Gen|Degree=Pos|Number=Plur\n",
      "             кварков NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur\n",
      "                   — PUNCT\n",
      "            t-кварка X|Foreign=Yes\n",
      "                   и CCONJ\n",
      "            b-кварка X|Foreign=Yes\n",
      "                   . PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc_sm.sents[0].morph.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-california",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gross-quantity",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocToken(start=2, stop=17, text='Асимптотическая', pos='ADJ', feats=<Acc,Pos,Fem,Sing>, lemma='асимптотический'),\n",
       " DocToken(start=18, stop=30, text='безопасность', pos='NOUN', feats=<Inan,Acc,Fem,Sing>, lemma='безопасность'),\n",
       " DocToken(start=31, stop=40, text='квантовой', pos='ADJ', feats=<Gen,Pos,Fem,Sing>, lemma='квантовый'),\n",
       " DocToken(start=41, stop=51, text='гравитации', pos='NOUN', feats=<Inan,Gen,Fem,Sing>, lemma='гравитация'),\n",
       " DocToken(start=52, stop=59, text='связала', pos='VERB', feats=<Perf,Fem,Ind,Sing,Past,Fin,Act>, lemma='связать'),\n",
       " DocToken(start=60, stop=66, text='заряды', pos='NOUN', feats=<Inan,Acc,Masc,Plur>, lemma='заряд'),\n",
       " DocToken(start=67, stop=68, text='и', pos='CCONJ', lemma='и'),\n",
       " DocToken(start=69, stop=74, text='массы', pos='NOUN', feats=<Inan,Acc,Fem,Plur>, lemma='масса'),\n",
       " DocToken(start=75, stop=82, text='тяжелых', pos='ADJ', feats=<Gen,Pos,Plur>, lemma='тяжелый'),\n",
       " DocToken(start=83, stop=90, text='кварков', pos='NOUN', feats=<Inan,Gen,Masc,Plur>, lemma='кварк')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for token in doc_sm.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "\n",
    "doc_sm.tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wired-replacement",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('временну́й', 't-кварка', 'физики-теоретики')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemms = {_.text: _.lemma for _ in doc_sm.tokens}\n",
    "lemms['временну́ю'], lemms['t-кварка'], lemms['Физики-теоретики']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prepared-equipment",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Используя экспериментально измеренное значение этого заряда, вычисляя бета-функцию в однопетлевом приближении и прослеживая поток ренормализационной группы до планковских масштабов энергий, физики рассчитали значение одного из этих параметров.',\n",
       " DocSent(start=6067, stop=6310, text='Используя экспериментально измеренное значение эт..., tokens=[...]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = doc_sm.sents[35]\n",
    "target.text, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "streaming-friday",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'использовать экспериментально измерить значение этот заряд , вычислять бета-функция в однопетлевой приближение и прослеживая поток ренормализационный группа до планковский масштаб энергия , физик рассчитать значение один из этот параметр .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([i.lemma for i in target.tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-enzyme",
   "metadata": {},
   "source": [
    "### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "corporate-lincoln",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────► Используя          advcl\n",
      "│                    экспериментально   \n",
      "│                 ┌─ измеренное         \n",
      "│               ┌─└► значение           obj\n",
      "│               │ ┌► этого              det\n",
      "│ ┌────────────►│ └─ заряда             nmod\n",
      "│ │             │ ┌► ,                  punct\n",
      "│ │ ┌─┌─┌───┌─┌─└►└─ вычисляя           acl\n",
      "│ │ │ │ │   │ │ └──► бета-функцию       obj\n",
      "│ │ │ │ │   │ │ ┌──► в                  case\n",
      "│ │ │ │ │   │ │ │ ┌► однопетлевом       amod\n",
      "│ │ │ │ │ ┌─│ └►└─└─ приближении        obl\n",
      "│ │ │ │ │ │ │     ┌► и                  cc\n",
      "│ │ │ │ │ │ └────►└─ прослеживая        conj\n",
      "│ │ │ │ └►│     ┌─── поток              obj\n",
      "│ │ │ │   │     │ ┌► ренормализационной amod\n",
      "│ │ │ │   │     └►└─ группы             nmod\n",
      "│ │ │ │   └────────► до                 case\n",
      "│ │ │ │           ┌► планковских        amod\n",
      "│ │ │ └────────►┌─└─ масштабов          obl\n",
      "│ │ │           └──► энергий            nmod\n",
      "│ │ └──────────────► ,                  punct\n",
      "│ │               ┌► физики             nsubj\n",
      "└─│         ┌───┌─└─ рассчитали         \n",
      "  │         │   └►┌─ значение           obj\n",
      "  └─────────│ ┌───└► одного             nmod\n",
      "            │ │ ┌──► из                 case\n",
      "            │ │ │ ┌► этих               det\n",
      "            │ └►└─└─ параметров         nmod\n",
      "            └──────► .                  punct\n"
     ]
    }
   ],
   "source": [
    "doc_sm.parse_syntax(syntax_parser)\n",
    "doc_sm.sents[35].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "satisfied-arthritis",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyntaxMarkup(\n",
       "    tokens=[SyntaxToken(\n",
       "         id='36_1',\n",
       "         text='Используя',\n",
       "         head_id='36_24',\n",
       "         rel='advcl'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_2',\n",
       "         text='экспериментально',\n",
       "         head_id='36_1',\n",
       "         rel='advmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_3',\n",
       "         text='измеренное',\n",
       "         head_id='36_0',\n",
       "         rel='root'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_4',\n",
       "         text='значение',\n",
       "         head_id='36_3',\n",
       "         rel='obj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_5',\n",
       "         text='этого',\n",
       "         head_id='36_6',\n",
       "         rel='det'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_6',\n",
       "         text='заряда',\n",
       "         head_id='36_26',\n",
       "         rel='nmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_7',\n",
       "         text=',',\n",
       "         head_id='36_8',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_8',\n",
       "         text='вычисляя',\n",
       "         head_id='36_4',\n",
       "         rel='acl'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_9',\n",
       "         text='бета-функцию',\n",
       "         head_id='36_8',\n",
       "         rel='obj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_10',\n",
       "         text='в',\n",
       "         head_id='36_12',\n",
       "         rel='case'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_11',\n",
       "         text='однопетлевом',\n",
       "         head_id='36_12',\n",
       "         rel='amod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_12',\n",
       "         text='приближении',\n",
       "         head_id='36_8',\n",
       "         rel='obl'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_13',\n",
       "         text='и',\n",
       "         head_id='36_14',\n",
       "         rel='cc'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_14',\n",
       "         text='прослеживая',\n",
       "         head_id='36_8',\n",
       "         rel='conj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_15',\n",
       "         text='поток',\n",
       "         head_id='36_8',\n",
       "         rel='obj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_16',\n",
       "         text='ренормализационной',\n",
       "         head_id='36_17',\n",
       "         rel='amod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_17',\n",
       "         text='группы',\n",
       "         head_id='36_15',\n",
       "         rel='nmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_18',\n",
       "         text='до',\n",
       "         head_id='36_12',\n",
       "         rel='case'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_19',\n",
       "         text='планковских',\n",
       "         head_id='36_20',\n",
       "         rel='amod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_20',\n",
       "         text='масштабов',\n",
       "         head_id='36_8',\n",
       "         rel='obl'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_21',\n",
       "         text='энергий',\n",
       "         head_id='36_20',\n",
       "         rel='nmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_22',\n",
       "         text=',',\n",
       "         head_id='36_8',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_23',\n",
       "         text='физики',\n",
       "         head_id='36_24',\n",
       "         rel='nsubj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_24',\n",
       "         text='рассчитали',\n",
       "         head_id='36_0',\n",
       "         rel='root'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_25',\n",
       "         text='значение',\n",
       "         head_id='36_24',\n",
       "         rel='obj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_26',\n",
       "         text='одного',\n",
       "         head_id='36_25',\n",
       "         rel='nmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_27',\n",
       "         text='из',\n",
       "         head_id='36_29',\n",
       "         rel='case'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_28',\n",
       "         text='этих',\n",
       "         head_id='36_29',\n",
       "         rel='det'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_29',\n",
       "         text='параметров',\n",
       "         head_id='36_26',\n",
       "         rel='nmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='36_30',\n",
       "         text='.',\n",
       "         head_id='36_24',\n",
       "         rel='punct'\n",
       "     )]\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sm.sents[35].syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "invisible-sitting",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyntaxMarkup(\n",
       "    tokens=[SyntaxToken(\n",
       "         id='11_1',\n",
       "         text='Чтобы',\n",
       "         head_id='11_2',\n",
       "         rel='mark'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_2',\n",
       "         text='справиться',\n",
       "         head_id='11_8',\n",
       "         rel='advcl'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_3',\n",
       "         text='с',\n",
       "         head_id='11_5',\n",
       "         rel='case'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_4',\n",
       "         text='этой',\n",
       "         head_id='11_5',\n",
       "         rel='det'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_5',\n",
       "         text='проблемой',\n",
       "         head_id='11_2',\n",
       "         rel='obl'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_6',\n",
       "         text=',',\n",
       "         head_id='11_2',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_7',\n",
       "         text='физики',\n",
       "         head_id='11_8',\n",
       "         rel='nsubj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_8',\n",
       "         text='считают',\n",
       "         head_id='11_0',\n",
       "         rel='root'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_9',\n",
       "         text=',',\n",
       "         head_id='11_16',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_10',\n",
       "         text='что',\n",
       "         head_id='11_16',\n",
       "         rel='mark'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_11',\n",
       "         text='поля',\n",
       "         head_id='11_16',\n",
       "         rel='nsubj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_12',\n",
       "         text='свободных',\n",
       "         head_id='11_13',\n",
       "         rel='amod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_13',\n",
       "         text='теорий',\n",
       "         head_id='11_11',\n",
       "         rel='nmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_14',\n",
       "         text='слабо',\n",
       "         head_id='11_16',\n",
       "         rel='advmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_15',\n",
       "         text='«',\n",
       "         head_id='11_16',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_16',\n",
       "         text='цепляются',\n",
       "         head_id='11_8',\n",
       "         rel='ccomp'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_17',\n",
       "         text='»',\n",
       "         head_id='11_16',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_18',\n",
       "         text='друг',\n",
       "         head_id='11_16',\n",
       "         rel='obl'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_19',\n",
       "         text='за',\n",
       "         head_id='11_18',\n",
       "         rel='fixed'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_20',\n",
       "         text='друга',\n",
       "         head_id='11_18',\n",
       "         rel='fixed'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_21',\n",
       "         text=',',\n",
       "         head_id='11_24',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_22',\n",
       "         text='а',\n",
       "         head_id='11_24',\n",
       "         rel='cc'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_23',\n",
       "         text='затем',\n",
       "         head_id='11_24',\n",
       "         rel='advmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_24',\n",
       "         text='вычисляют',\n",
       "         head_id='11_16',\n",
       "         rel='conj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_25',\n",
       "         text='поправки',\n",
       "         head_id='11_24',\n",
       "         rel='obj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_26',\n",
       "         text='к',\n",
       "         head_id='11_27',\n",
       "         rel='case'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_27',\n",
       "         text='пропагаторам',\n",
       "         head_id='11_29',\n",
       "         rel='amod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_28',\n",
       "         text='свободной',\n",
       "         head_id='11_29',\n",
       "         rel='amod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_29',\n",
       "         text='теории',\n",
       "         head_id='11_27',\n",
       "         rel='nmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_30',\n",
       "         text=';',\n",
       "         head_id='11_39',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_31',\n",
       "         text='чем',\n",
       "         head_id='11_39',\n",
       "         rel='mark'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_32',\n",
       "         text='более',\n",
       "         head_id='11_33',\n",
       "         rel='advmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_33',\n",
       "         text='высокие',\n",
       "         head_id='11_34',\n",
       "         rel='amod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_34',\n",
       "         text='порядки',\n",
       "         head_id='11_35',\n",
       "         rel='nsubj:pass'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_35',\n",
       "         text='учитываются',\n",
       "         head_id='11_8',\n",
       "         rel='ccomp'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_36',\n",
       "         text=',',\n",
       "         head_id='11_39',\n",
       "         rel='punct'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_37',\n",
       "         text='тем',\n",
       "         head_id='11_39',\n",
       "         rel='mark'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_38',\n",
       "         text='точнее',\n",
       "         head_id='11_39',\n",
       "         rel='advmod'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_39',\n",
       "         text='получается',\n",
       "         head_id='11_8',\n",
       "         rel='ccomp'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_40',\n",
       "         text='результат',\n",
       "         head_id='11_39',\n",
       "         rel='nsubj'\n",
       "     ),\n",
       "     SyntaxToken(\n",
       "         id='11_41',\n",
       "         text='.',\n",
       "         head_id='11_8',\n",
       "         rel='punct'\n",
       "     )]\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sm.sents[10].syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-haiti",
   "metadata": {},
   "source": [
    "### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "respective-approach",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Асимптотическая безопасность квантовой гравитации связала заряды и \n",
      "массы тяжелых кварков\n",
      "Matt Cummings / flickr.com\n",
      "Физики-теоретики из Германии использовали теорию асимптотически \n",
      "                    LOC─────                                    \n",
      "безопасной квантовой гравитации, чтобы рассчитать отношение масс двух \n",
      "самых тяжелых кварков — t-кварка и b-кварка. Для этого ученые \n",
      "отталкивались от известных значений абелева гиперзаряда и констант \n",
      "электрослабой и сильной связи и прослеживали поток ренормализационной \n",
      "группы вплоть до планковских масштабов энергии. Кроме того, \n",
      "исследователи показали, что отношения зарядов и масс кварков связаны \n",
      "между собой. Статья опубликована в Physical Review Letters и находится\n",
      "                                   ORG────────────────────            \n",
      " в свободном доступе.\n",
      "Одно из важнейших свойств Стандартной модели — это перенормируемость, \n",
      "то есть возможность избавляться от бесконечно расходящихся величин. \n",
      "Чтобы понять, в чем заключается идея перенормировок, сначала надо \n",
      "понять, откуда в теории берутся расходимости. Основным объектом \n",
      "Стандартной модели, как и любой квантовой теории поля, являются \n",
      "пропагаторы — функции, которые показывают вероятность перехода между \n",
      "различными конфигурациями квантовых полей. Например, вероятность \n",
      "частицы переместиться между двумя заданными точками за фиксированный \n",
      "промежуток времени. Для свободных теорий, в которых частицы не \n",
      "взаимодействуют друг с другом, найти пропагаторы очень легко — \n",
      "достаточно выписать и решить уравнения теории. Если же добавить в \n",
      "теорию взаимодействие, которое «перемешивает» поля — например, \n",
      "электромагнитное поле и поле электронов, — уравнения резко \n",
      "усложняются, и точно решить их становится невозможно. Чтобы справиться\n",
      " с этой проблемой, физики считают, что поля свободных теорий слабо \n",
      "«цепляются» друг за друга, а затем вычисляют поправки к пропагаторам \n",
      "свободной теории; чем более высокие порядки учитываются, тем точнее \n",
      "получается результат. Наглядно такое вычисление можно представить в \n",
      "виде диаграмм Фейнмана. При низких энергиях этот подход очень хорошо \n",
      "работает — в частности, теоретическое значение магнитного момента \n",
      "электрона совпадает с экспериментом с точностью порядка 10−12.\n",
      "Свободные пропагаторы в квантовой электродинамике (рисунок 2), \n",
      "вершина, описывающая взаимодействие электрона и фотона (рисунок 1) и \n",
      "процесс рассеяния фотона на электроне в древесном приближении (рисунок\n",
      " 3)\n",
      "Wikimedia Commons\n",
      "ORG──────────────\n",
      "Поделиться\n",
      "Петлевые поправки к процессу рассеяния фотона на электроне (рисунок 3 \n",
      "с предыдущей картинки)\n",
      "Wikimedia Commons\n",
      "ORG──────────────\n",
      "Поделиться\n",
      "1/2\n",
      "К сожалению, при больших энергиях (то есть на маленьких расстояниях) \n",
      "поправки к пропагаторам бесконечно растут, что противоречит \n",
      "экспериментальным данным. Чтобы убрать эти расходимости, физики \n",
      "определенным образом «подкручивают» напряженности полей и постоянных \n",
      "теории, которые входили в исходные уравнения движения, заставляя их \n",
      "зависеть от масштаба энергий. Другими словами, в результате этой \n",
      "процедуры ученые выделяют в пропагаторах физически осмысленные вклады \n",
      "и добавляют в исходный лагранжиан теории специально подобранные \n",
      "контрчлены, которые сокращают «нефизичные» расходимости. В этом \n",
      "заключается смысл процедуры перенормировки. Если число контрчленов \n",
      "конечно, то теория «хорошая», и с ее помощью можно рассчитать значения\n",
      " наблюдаемых величин. Стандратная модель относится именно к такому \n",
      "типу теорий. Если же расходимости можно убрать только с помощью \n",
      "бесконечного числа контрчленов, то предсказательная сила теории равна \n",
      "нулю, поскольку она требует вводить бесконечное число свободных \n",
      "параметров. Это случай квантовой гравитации. Физики пытались решить \n",
      "эту проблему, разработав принципиально новые экзотические теории — \n",
      "например, теорию струн или теорию петлевой квантовой гравитации. Тем \n",
      "не менее, до сих пор не существует экспериментов, которые подтвердили \n",
      "бы эти теории.\n",
      "С другой стороны, в конце 1970-х годов Стивен Вайнберг заметил, что \n",
      "                                       PER────────────              \n",
      "неперенормируемость теории квантовой гравитации не обязательно \n",
      "означает, что с ее помощью нельзя рассчитывать значения наблюдаемых \n",
      "величин. Вместо того чтобы бороться с расходимостями, возникающими в \n",
      "стандартных методах, Вайнберг предложил «зайти» с противоположного \n",
      "                     PER─────                                      \n",
      "конца — описать теорию с помощью конечного числа конечных параметров \n",
      "на больших энергиях, а потом продолжить зависимости в область низких \n",
      "энергий. Такое свойство теории Вайнберг назвал асимптотической \n",
      "                               PER─────                        \n",
      "безопасностью по аналогии с асимптотической свободой Квантовой \n",
      "хромодинамики, в которой константа связи стремится к нулю на больших \n",
      "энергиях. Математический инструмент, который позволяет выполнить такие\n",
      " расчеты, предложили в начале 1990-х годов Кристоф Веттерих (Christof \n",
      "                                           PER────────────────────────\n",
      "Wetterich) и Мартин Рейтер (Martin Reuter). В 2009 году Михаил \n",
      "──────────   PER──────────────────────────              PER────\n",
      "Шапошников и Кристов Веттерих рассчитали с помощью теории \n",
      "──────────   PER─────────────                             \n",
      "асимптотически безопасной гравитации предполагаемую массу бозона \n",
      "Хиггса, которая составила примерно 126 гигаэлектронвольт, что \n",
      "PER───                                                        \n",
      "практически в точности совпадает с результатами последовавших \n",
      "измерений на Большом адронном коллайдере. Кроме того, теория с \n",
      "асимптотической безопасностью практически не нужно вводить новые \n",
      "частицы, как это предлагает делать большинство альтернативных теорий \n",
      "вроде теории струн. Это делает идею асимптотической безопасности очень\n",
      " привлекательной для теоретиков.\n",
      "В новой статье физики Астрид Эйххорн (Astrid Eichhorn) и Аарон Хельд \n",
      "                      PER─────────────────────────────   PER─────────\n",
      "(Aaron Held) использовали асимптотически безопасную гравитацию, чтобы \n",
      "────────────                                                          \n",
      "объяснить огромный разрыв масс между двумя самыми массивными кварками \n",
      "— t-кварком (mt ≈ 173 гигаэлектронвольт) и b-кварком (mb ≈ 4,9 \n",
      "гигаэлектронвольт). В Стандартной модели массы кварков возникают из-за\n",
      " того, что частицы «цепляются» за поле Хиггса, равномерно заполняющего\n",
      "                                       PER───                         \n",
      " Вселенную (подробнее про этот эффект можно прочитать в материале «С \n",
      "днем рождения, БАК!»). Сила, с которой кварки «цепляются» к полю, \n",
      "определяется юкавскими константами связи yb и yt, значения которых \n",
      "невозможно рассчитать в рамках Стандартной модели. С другой стороны, \n",
      "эти константы должны быть связаны с абелевым гиперзарядом соотношением\n",
      " yt2 — yb2 = ⅓gy2, которое выполняется для очень больших энергий \n",
      "(много больше планковского масштаба). В то же время, абелев гиперзаряд\n",
      " связан с параметрами квантовой гравитации. Используя экспериментально\n",
      " измеренное значение этого заряда, вычисляя бета-функцию в \n",
      "однопетлевом приближении и прослеживая поток ренормализационной группы\n",
      " до планковских масштабов энергий, физики рассчитали значение одного \n",
      "из этих параметров. Значение второго параметра ученые зафиксировали \n",
      "исходя из массы b-кварка. Наконец, исследователи рассчитали массу \n",
      "t-кварка, используя найденные значения параметров, и получили величину\n",
      " около mt ≈ 178 гигаэлектронвольт, что хорошо согласуется с \n",
      "экспериментом.\n",
      "Зависимости параметров Стандартной модели от масштаба энергий, \n",
      "рассчитанные учеными в рамках асимптотически безопасной теории \n",
      "квантовой гравитации\n",
      "A. Eichhorn & A. Held / Physical Review Letters\n",
      "Поделиться\n",
      "Кроме того, из расчетов физиков следует еще три интересных замечания. \n",
      "Во-первых, постоянные квантовой гравитации для абелевых и неабелевых \n",
      "полей должны быть очень близки — это согласуется с тем, что \n",
      "гравитационные поля одинаково сильно взаимодействуют с частицами \n",
      "разной природы, если они имеют одинаковую массу. Во-вторых, \n",
      "характерный масштаб энергий, на которых гравитационные вклады \n",
      "«выключаются», совпадает с планковской энергией. В-третьих, заряды \n",
      "t-кварка и b-кварка должны относиться как Qt/Qb = −2. Если бы хотя бы \n",
      "одно из этих трех предположений не выполнялось, отношение масс кварков\n",
      " получились бы совершенно другим — исправить расхождение не помогло бы\n",
      " даже изменение параметров квантовой гравитации.\n",
      "Несмотря на то, что эффекты квантовой гравитации должны очень слабо \n",
      "проявляться на наблюдаемых масштабах энергии, физики все равно \n",
      "пытаются их обнаружить, измеряя тонкие эффекты с высокой точностью. \n",
      "Например, отслеживают расстояние до Луны и колебания приливных сил, \n",
      "                                    LOC─                            \n",
      "перепроверяют классические предсказания ОТО и сравнивают временну́ю \n",
      "задержку между фотонами, приходящими от далеких гамма-всплесков. Как и\n",
      " ожидалось, ни один из этих экспериментов не нашел отклонений от \n",
      "Стандартной модели или ОТО.\n",
      "Дмитрий Трунин\n",
      "PER───────────\n"
     ]
    }
   ],
   "source": [
    "doc_sm.tag_ner(ner_tagger)\n",
    "doc_sm.ner.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-drink",
   "metadata": {},
   "source": [
    "### Named entity parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inner-tuner",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Стивен Вайнберг': {'first': 'Стивен', 'last': 'Вайнберг'},\n",
       " 'Вайнберг': {'last': 'Вайнберг'},\n",
       " 'Кристоф Веттерих (Christof Wetterich)': {'first': 'Кристоф',\n",
       "  'last': 'Веттерих'},\n",
       " 'Мартин Рейтер (Martin Reuter)': {'first': 'Мартин', 'last': 'Рейтер'},\n",
       " 'Михаил Шапошников': {'first': 'Михаил', 'last': 'Шапошников'},\n",
       " 'Кристов Веттерих': {'first': 'Веттерих', 'last': 'Кристов'},\n",
       " 'Астрид Эйххорн (Astrid Eichhorn)': {'first': 'Астрид', 'last': 'Эйххорн'},\n",
       " 'Аарон Хельд (Aaron Held)': {'first': 'Аарон', 'last': 'Хельд'},\n",
       " 'Дмитрий Трунин': {'first': 'Дмитрий', 'last': 'Трунин'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for span in doc_sm.spans:\n",
    "    span.normalize(morph_vocab)\n",
    "    if span.type == PER:\n",
    "        span.extract_fact(names_extractor)\n",
    "{_.normal: _.fact.as_dict for _ in doc_sm.spans if _.type == PER and _.fact}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-nightlife",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "grave-roommate",
   "metadata": {},
   "source": [
    "## Tiny text complexity estimation\n",
    "    @TinyComplEst\n",
    "\n",
    "> Estimate complexity of an article using self-defined parameters\n",
    "> (these are empirical parameters defined after 1 minute of thinking, don't consider them as a real complexity params)\n",
    "\n",
    "- Morphology: normalized (`token.lemma`) vocabulary size of an article\n",
    "- Morphology: median size of an each morph type word (`token.pos`)\n",
    "- Syntax: overlapping of syntax structure in one sent (`sent.syntax`)\n",
    "\n",
    "Using `nplus1` articles for estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "civil-reasoning",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import lxml.html as html\n",
    "import numpy as np\n",
    "\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "funded-center",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_article(url: str) -> str:\n",
    "    req = r.get(url)\n",
    "    if req.status_code == 200:\n",
    "        tree = html.document_fromstring(req.text)\n",
    "        ps = tree.xpath(\"//article//p[text()!='']\")\n",
    "        return ''.join([p.text_content() for p in ps]).replace('\\xa0', ' ')\n",
    "    else:\n",
    "        raise Exception(req.status_code, req)\n",
    "\n",
    "def parse_article(page: str) -> Doc:\n",
    "    doc = Doc(page)\n",
    "    \n",
    "    # segmentation for tokent and sents\n",
    "    doc.segment(seg)\n",
    "    \n",
    "    # morph\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    \n",
    "    # lemmatize\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    \n",
    "    # syntax\n",
    "    doc.parse_syntax(syntax_parser)\n",
    "\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "foreign-criminal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_score(doc: Doc) -> float:\n",
    "    def get_voc_stats(doc: Doc) -> object:\n",
    "        '''\n",
    "        Returns basic vocabulary stats\n",
    "        '''\n",
    "\n",
    "        stats = ['median_size', 'mean_size',\n",
    "                 'min_size', 'max_size',\n",
    "                 'uniq_size', 'uniq_coeff']\n",
    "        VocStats = namedtuple('VocStats', stats)\n",
    "\n",
    "        lemms = [t.lemma for t in doc.tokens if len(t.lemma) > 1]\n",
    "        sizes = np.array([len(t) for t in lemms])\n",
    "        \n",
    "        median, mean = np.median(sizes), sizes.mean()\n",
    "        min_, max_ = sizes.min(), sizes.max()\n",
    "        \n",
    "        uniq_lemms = set(lemms)\n",
    "        uniq_size = len(uniq_lemms)\n",
    "        uniq_coeff = uniq_size / len(lemms)\n",
    "        \n",
    "        stats_vals = [median, mean, min_, max_, uniq_size, uniq_coeff]\n",
    "        return VocStats(*stats_vals)\n",
    "    \n",
    "    def get_morph_stats(doc: Doc) -> object:\n",
    "        '''\n",
    "        Returns basic morph parts stats\n",
    "        \n",
    "        dict with median size for each morph type\n",
    "        '''\n",
    "        \n",
    "        stats = ['pos_median_sizes']\n",
    "        MorphStats = namedtuple('MorphStats', stats)\n",
    "        \n",
    "        sizes = {}\n",
    "        for t in doc.tokens:\n",
    "            if t.pos == 'PUNCT':\n",
    "                continue\n",
    "            if t.pos not in sizes:\n",
    "                sizes[t.pos] = []\n",
    "            \n",
    "            sizes[t.pos].append(len(t.lemma))\n",
    "        \n",
    "        median_sizes = {k:np.median(v) for k, v in sizes.items()}\n",
    "\n",
    "        stats_vals = [median_sizes]\n",
    "        return MorphStats(*stats_vals)\n",
    "        \n",
    "\n",
    "    def get_syntax_stats(doc: Doc) -> object:\n",
    "        '''\n",
    "        Returns syntax ovelapping stats for each sentence\n",
    "        '''\n",
    "        \n",
    "        stats = ['ovlp_median', 'ovlp_max']\n",
    "        SyntaxStats = namedtuple('SyntaxStats', stats)\n",
    "        \n",
    "        overlappings = []\n",
    "        for sent in doc.sents:\n",
    "            \n",
    "            syntax_intervals = []\n",
    "            for t in sent.syntax.tokens:\n",
    "                id = int(t.id.split('_')[1])\n",
    "                head_id = int(t.head_id.split('_')[1])\n",
    "                \n",
    "                if head_id > id:\n",
    "                    id, head_id = head_id, id\n",
    "                \n",
    "                syntax_intervals.append((head_id, 0))\n",
    "                syntax_intervals.append((id, 1))\n",
    "\n",
    "            syntax_intervals.sort(key=lambda x: x[0])\n",
    "            \n",
    "            # calc max intersections in all syntax intervals\n",
    "            cnt, mx = 0, 0\n",
    "            for i in syntax_intervals:\n",
    "                if i[1]:\n",
    "                    mx = max(mx, cnt)\n",
    "                    cnt -= 1\n",
    "                else:\n",
    "                    cnt += 1\n",
    "            \n",
    "            overlappings.append(mx)\n",
    "                \n",
    "        median_overlap = np.median(overlappings)\n",
    "        max_overlap = np.max(overlappings)\n",
    "        \n",
    "        stats_vals = [median_overlap, max_overlap]\n",
    "        return SyntaxStats(*stats_vals)\n",
    "    \n",
    "    def complexity(doc: Doc) -> float:\n",
    "        '''\n",
    "        Estimates `complexity` for given document\n",
    "        returns float in range [0, 1]\n",
    "        '''\n",
    "        print('-'*10)\n",
    "        # RELU = lambda m: lambda x: np.max(0, (x-m))\n",
    "        SIGM = lambda m, beta: lambda x: 1/(1+np.exp(-beta * (x-m)))\n",
    "\n",
    "        voc, morph, syntax = get_voc_stats(doc), get_morph_stats(doc), get_syntax_stats(doc)\n",
    "        print('voc stats\\n', voc)\n",
    "        print('morph stats\\n', morph)\n",
    "        print('syntax stats\\n', syntax)\n",
    "        \n",
    "        # vocabulary complexity score\n",
    "        voc_var = (voc.max_size - voc.min_size) * voc.mean_size/voc.median_size\n",
    "        voc_var *= voc.uniq_coeff\n",
    "        print('voc_var:', voc_var)\n",
    "        print()\n",
    "\n",
    "        voc_score = SIGM(9, 1)(voc_var)\n",
    "        print('VOC SCORE:', voc_score)\n",
    "        \n",
    "        # morph complexity score\n",
    "        pos_metric = {\n",
    "            'NOUN': SIGM(6, 1),\n",
    "            'NUM': SIGM(1, 0.5),\n",
    "            'ADJ': SIGM(6, 0.7),\n",
    "            'VERB': SIGM(3, 2),\n",
    "            'X': SIGM(3, 2),\n",
    "            'ADV': SIGM(6, 2),\n",
    "        }\n",
    "        metrics = [func(morph.pos_median_sizes[part]) for part, func in pos_metric.items() if part in morph.pos_median_sizes]\n",
    "        morph_var = np.sum(metrics)\n",
    "        morph_var /= len(metrics)\n",
    "        \n",
    "        morph_score = morph_var\n",
    "        print('MORPH SCORE:', morph_var)\n",
    "        \n",
    "        # syntax overlapping score\n",
    "        sigm = SIGM(syntax.ovlp_median, syntax.ovlp_max/len(doc.sents))\n",
    "        syntax_score = sigm(syntax.ovlp_max-syntax.ovlp_median)\n",
    "        print('SYNTAX SCORE:', syntax_score)\n",
    "\n",
    "        print('-'*10)\n",
    "        return (voc_score*0.4 + morph_score*0.2 + syntax_score*0.4) * 10\n",
    "    \n",
    "    return complexity(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "thorough-patient",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    ('https://nplus1.ru/news/2021/11/13/pingu', 1.3),\n",
    "    ('https://nplus1.ru/news/2021/11/12/mummified-children', 2.2),\n",
    "    ('https://nplus1.ru/news/2021/10/20/homeland-horse', 3.3),\n",
    "    ('https://nplus1.ru/news/2021/11/13/birdswings', 4.3),\n",
    "    ('https://nplus1.ru/news/2021/10/18/domain-video', 5.3),\n",
    "    ('https://nplus1.ru/news/2021/11/11/black-holes-cosmology-growth', 6.3),\n",
    "    ('https://nplus1.ru/news/2021/10/29/big-n-ionization', 7.3),\n",
    "    ('https://nplus1.ru/news/2021/11/09/neutron-oscillation', 8.3),\n",
    "    ('https://nplus1.ru/news/2018/10/25/link', 9.3),\n",
    "    ('https://nplus1.ru/news/2016/03/31/methade', 9.6),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "diagnostic-isaac",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading articles\n",
    "downloaded_urls = [\n",
    "    (load_article(url), score) for url, score in urls\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-penny",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_articles = [\n",
    "    (parse_article(art), score) for art, score in downloaded_urls\n",
    "]\n",
    "parsed_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "moving-publication",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=6.0, mean_size=6.185882352941176, min_size=2, max_size=17, uniq_size=278, uniq_coeff=0.6541176470588236)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 6.0, 'NUM': 3.0, 'NOUN': 7.0, 'X': 7.0, 'ADP': 1.0, 'ADJ': 7.0, 'VERB': 8.0, 'CCONJ': 1.0, 'ADV': 6.0, 'SCONJ': 3.0, 'PRON': 3.0, 'AUX': 4.0, 'PART': 2.0, 'DET': 3.5})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=7.0, ovlp_max=12)\n",
      "voc_var: 10.115737024221453\n",
      "\n",
      "VOC SCORE: 0.7531971223166561\n",
      "MORPH SCORE: 0.7716540302381678\n",
      "SYNTAX SCORE: 0.2689414213699951\n",
      "----------\n",
      "MY SCORE 5.631862235222941\n",
      "NPLUS1 SCORE 1.3\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=7.0, mean_size=6.8782383419689115, min_size=2, max_size=19, uniq_size=252, uniq_coeff=0.6528497409326425)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 7.0, 'NUM': 2.0, 'NOUN': 7.0, 'X': 7.0, 'ADV': 5.0, 'VERB': 9.0, 'ADJ': 7.0, 'ADP': 1.0, 'SCONJ': 3.0, 'DET': 3.5, 'CCONJ': 1.0, 'PRON': 3.0, 'AUX': 4.0, 'PART': 2.0, 'SYM': 1.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=6.0, ovlp_max=17)\n",
      "voc_var: 10.90539343338076\n",
      "\n",
      "VOC SCORE: 0.8705007389769005\n",
      "MORPH SCORE: 0.6900945182861791\n",
      "SYNTAX SCORE: 0.9911830412412388\n",
      "----------\n",
      "MY SCORE 8.826924157444916\n",
      "NPLUS1 SCORE 2.2\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=6.0, mean_size=6.611854684512428, min_size=2, max_size=18, uniq_size=281, uniq_coeff=0.5372848948374761)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 6.0, 'NUM': 3.0, 'NOUN': 6.0, 'ADJ': 8.0, 'ADP': 2.0, 'X': 5.0, 'VERB': 9.0, 'SCONJ': 3.0, 'ADV': 6.0, 'PRON': 3.0, 'DET': 3.0, 'CCONJ': 1.0, 'AUX': 4.0, 'PART': 3.0, 'SYM': 1.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=7.0, ovlp_max=16)\n",
      "voc_var: 9.473199063597157\n",
      "\n",
      "VOC SCORE: 0.6161406518104988\n",
      "MORPH SCORE: 0.7525416855086487\n",
      "SYNTAX SCORE: 0.8106969983141019\n",
      "----------\n",
      "MY SCORE 7.2124339715157015\n",
      "NPLUS1 SCORE 3.3\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=6.0, mean_size=6.3, min_size=2, max_size=18, uniq_size=225, uniq_coeff=0.5921052631578947)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 7.0, 'CCONJ': 1.0, 'NOUN': 6.0, 'NUM': 2.0, 'X': 6.0, 'ADJ': 8.0, 'VERB': 9.0, 'ADV': 6.0, 'SCONJ': 3.0, 'ADP': 2.0, 'PRON': 3.0, 'DET': 4.0, 'AUX': 4.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=6.0, ovlp_max=12)\n",
      "voc_var: 9.947368421052632\n",
      "\n",
      "VOC SCORE: 0.7205856384145326\n",
      "MORPH SCORE: 0.7370274087381999\n",
      "SYNTAX SCORE: 0.5\n",
      "----------\n",
      "MY SCORE 6.3563973711345305\n",
      "NPLUS1 SCORE 4.3\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=7.0, mean_size=7.395793499043977, min_size=2, max_size=20, uniq_size=308, uniq_coeff=0.5889101338432122)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 6.5, 'NUM': 2.0, 'NOUN': 8.0, 'X': 7.0, 'ADJ': 10.0, 'VERB': 9.0, 'ADP': 1.0, 'PRON': 3.0, 'SCONJ': 4.0, 'CCONJ': 1.0, 'ADV': 5.0, 'PART': 2.0, 'DET': 4.0, 'AUX': 4.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=6.0, ovlp_max=13)\n",
      "voc_var: 11.199748472739635\n",
      "\n",
      "VOC SCORE: 0.9002269213755224\n",
      "MORPH SCORE: 0.7607989434996529\n",
      "SYNTAX SCORE: 0.6322000416345195\n",
      "----------\n",
      "MY SCORE 7.651305739039474\n",
      "NPLUS1 SCORE 5.3\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=6.0, mean_size=6.591216216216216, min_size=2, max_size=16, uniq_size=312, uniq_coeff=0.527027027027027)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 5.0, 'NUM': 3.0, 'NOUN': 6.0, 'X': 5.0, 'VERB': 9.0, 'ADJ': 7.0, 'ADP': 1.0, 'DET': 4.0, 'PRON': 3.0, 'SCONJ': 3.0, 'CCONJ': 1.0, 'ADV': 6.0, 'PART': 2.0, 'SYM': 1.0, 'AUX': 4.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=8.0, ovlp_max=21)\n",
      "voc_var: 8.105414536157777\n",
      "\n",
      "VOC SCORE: 0.29016445585439204\n",
      "MORPH SCORE: 0.7302089994435795\n",
      "SYNTAX SCORE: 0.9933071490757153\n",
      "----------\n",
      "MY SCORE 6.594304418607589\n",
      "NPLUS1 SCORE 6.3\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=7.0, mean_size=7.11, min_size=2, max_size=25, uniq_size=349, uniq_coeff=0.49857142857142855)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 5.0, 'NUM': 3.0, 'NOUN': 7.0, 'X': 2.0, 'ADJ': 9.0, 'VERB': 9.0, 'PRON': 3.0, 'ADV': 5.0, 'ADP': 1.0, 'DET': 4.0, 'SCONJ': 3.0, 'PART': 2.0, 'AUX': 4.0, 'CCONJ': 1.0, 'SYM': 1.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=6.0, ovlp_max=15)\n",
      "voc_var: 11.64734081632653\n",
      "\n",
      "VOC SCORE: 0.9338469038805759\n",
      "MORPH SCORE: 0.5985700059890049\n",
      "SYNTAX SCORE: 0.7713969883819073\n",
      "----------\n",
      "MY SCORE 8.018115581027942\n",
      "NPLUS1 SCORE 7.3\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=7.0, mean_size=7.423387096774194, min_size=2, max_size=22, uniq_size=291, uniq_coeff=0.5866935483870968)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 6.0, 'VERB': 9.0, 'NUM': 3.0, 'NOUN': 8.0, 'X': 6.5, 'ADJ': 10.0, 'ADP': 2.0, 'PRON': 3.0, 'CCONJ': 1.0, 'ADV': 5.0, 'SCONJ': 3.0, 'AUX': 4.0, 'DET': 3.0, 'PART': 3.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=6.5, ovlp_max=9)\n",
      "voc_var: 12.443580905306971\n",
      "\n",
      "VOC SCORE: 0.9690391318450355\n",
      "MORPH SCORE: 0.778802867893689\n",
      "SYNTAX SCORE: 0.20026877155592115\n",
      "----------\n",
      "MY SCORE 6.2348373493912055\n",
      "NPLUS1 SCORE 8.3\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=5.0, mean_size=6.123222748815166, min_size=2, max_size=19, uniq_size=340, uniq_coeff=0.5371248025276462)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'PROPN': 6.5, 'CCONJ': 1.0, 'NOUN': 6.0, 'NUM': 3.0, 'ADJ': 7.0, 'VERB': 8.0, 'ADP': 1.0, 'PRON': 3.0, 'SCONJ': 3.0, 'X': 4.0, 'DET': 4.0, 'PART': 2.0, 'AUX': 4.0, 'ADV': 5.0, 'SYM': 1.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=7.0, ovlp_max=20)\n",
      "voc_var: 11.182378353286463\n",
      "\n",
      "VOC SCORE: 0.8986558824957035\n",
      "MORPH SCORE: 0.6498668254882447\n",
      "SYNTAX SCORE: 0.9685856289684298\n",
      "----------\n",
      "MY SCORE 8.768699696833023\n",
      "NPLUS1 SCORE 9.3\n",
      "\n",
      "----------\n",
      "voc stats\n",
      " VocStats(median_size=6.0, mean_size=6.864909390444811, min_size=2, max_size=18, uniq_size=332, uniq_coeff=0.5469522240527183)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'NOUN': 7.0, 'NUM': 5.0, 'PROPN': 5.0, 'ADJ': 8.0, 'SYM': 1.0, 'ADP': 1.0, 'VERB': 8.0, 'ADV': 5.0, 'SCONJ': 3.0, 'DET': 4.0, 'PART': 2.0, 'CCONJ': 1.0, 'PRON': 3.0, 'AUX': 4.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=7.0, ovlp_max=15)\n",
      "voc_var: 10.012739890731146\n",
      "\n",
      "VOC SCORE: 0.7335560078123055\n",
      "MORPH SCORE: 0.7066394138639768\n",
      "SYNTAX SCORE: 0.6265024826068166\n",
      "----------\n",
      "MY SCORE 6.8535127894044425\n",
      "NPLUS1 SCORE 9.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for doc, score in parsed_articles:\n",
    "    print('MY SCORE', get_score(doc))\n",
    "    print('NPLUS1 SCORE', score)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "attempted-colony",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = parse_article(art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "north-montana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voc stats\n",
      " VocStats(median_size=6.0, mean_size=6.718446601941747, min_size=2, max_size=18, uniq_size=313, uniq_coeff=0.5064724919093851)\n",
      "morph stats\n",
      " MorphStats(pos_median_sizes={'NOUN': 7.0, 'NUM': 3.0, 'PROPN': 6.0, 'ADJ': 9.0, 'ADP': 2.0, 'CCONJ': 1.0, 'VERB': 8.0, 'X': 12.0, 'PRON': 3.0, 'SCONJ': 3.0, 'ADV': 8.0, 'DET': 4.0, 'AUX': 4.0, 'PART': 2.0})\n",
      "syntax stats\n",
      " SyntaxStats(ovlp_median=7.0, ovlp_max=14)\n",
      "voc_var: 9.073889045988208\n",
      "VOC SCORE: 0.51846386183333\n",
      "MORPH SCORE: 0.692534037437163\n",
      "SYNTAX SCORE: 0.9706877692486436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "nervous-member",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "quiet-malta",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                        Зоология\\n                                            \\n            \\n                \\n                    23:46\\n                    13 Нояб. 2021\\n                \\n            \\n        \\n            \\n                Сложность\\n                1.3\\n            \\n        Пингвин Адели (Pygoscelis adeliae) на Южных Шетландских островах.Wikimedia CommonsВ\\xa0Новой Зеландии в\\xa0третий раз в\\xa0истории встретили пингвина Адели. В норме представители данного вида живут в\\xa0Антарктиде и\\xa0Субантарктике, в\\xa0трех тысячах километров южнее. Специалисты полагают, что к\\xa0новозеландскому побережью прибило молодую особь, которая выплыла слишком далеко в\\xa0океан и\\xa0была подхвачена течением. Как сообщает The Guardian, заблудившегося пингвина осмотрел ветеринар, после чего птицу напоили водой, накормили рыбой и\\xa0выпустили на волю.Жителя Новой Зеландии трудно удивить встречей с\\xa0пингвином. Только на\\xa0главных островах архипелага гнездятся три вида этих птиц, а\\xa0еще несколько населяют отдаленные островные группы, такие как Чатем и\\xa0Снэрс. Впрочем, порой у\\xa0новозеландских берегов появляются пингвины, основной ареал которых находится за\\xa0тысячи километров отсюда.Один из\\xa0таких необычных гостей посетил юго-восточное побережье Новой Зеландии несколько дней назад. Первыми птицу заметили (и сняли на видео) Гарри Сингх (Harry Singh) и\\xa0его жена, которые прогуливались у\\xa0моря близ поселения Бёрдингс-Флэт (Birdlings Flat) к\\xa0югу от города Крайстчерч. Пингвин стоял у\\xa0воды неподвижно\\xa0и, пока он\\xa0не\\xa0пошевелил головой, супруги даже думали, что это забытая кем-то мягкая игрушка. Синхг заметил что птица, которой он дал прозвище Пингу, выглядит одинокой и измученной. Кроме того, она не\\xa0входила в\\xa0воду около часа, так что могла стать легкой жертвой бродячих собак.В\\xa0попытке помочь Пингу Сингх в\\xa0тот\\xa0же день обратился в\\xa0расположенный в\\xa0Крайстчерче центр реабилитации пингвинов. На\\xa0его зов откликнулся опытный сотрудник Томас Стрэк (Thomas Stracke), который помогает пингвинам уже около десяти лет. Прибыв на\\xa0побережье близ Бёрдингc-Флэт с\\xa0ветеринаром, Стрэк с удивлением обнаружил, что Пингу\\xa0— пингвин Адели (Pygoscelis adeliae). Данный вид гнездится Антарктиде и\\xa0на\\xa0некоторых субантарктических островах. В\\xa0Новой Зеландии пингвины Адели не\\xa0обитают. Более того, до\\xa0сих пор их\\xa0встречали здесь всего дважды: в\\xa01962 и\\xa01993\\xa0годах.Чтобы добраться до\\xa0Бёрдингc-Флэт, Пингу пришлось преодолеть вплавь около трех тысяч километров. Судя по\\xa0всему, Пингу\\xa0— молодая особь, которая отплыла далеко от\\xa0побережья Антарктиды и\\xa0была унесена течением в\\xa0сторону Новой Зеландии.Стрэк и\\xa0ветеринар поймали пингвина и\\xa0осмотрели его. Оказалось, что птица немного истощена и\\xa0обезвожена, однако в\\xa0целом ее\\xa0состояние не\\xa0вызвало у\\xa0специалистов опасений. Пингу дали воды и\\xa0рыбной кашицы, а\\xa0затем выпустили на\\xa0морскому берегу в\\xa0надежде, что он\\xa0найдет путь домой. По\\xa0словам Стрэка, он\\xa0планировал организовать доставку пингвина вертолетом на\\xa0новозеландскую антарктическую станцию Скотт-Бейс, но\\xa0ему дали понять, что это невозможно.Пингвины Адели, как и\\xa0другие пингвины, испытывают на\\xa0себе последствия антропогенных изменений климата. Однако на данный вид они оказывают неоднозначное влияние. Если популяции пингвинов Адели с\\xa0Антарктического полуострова теперь чаще сталкиваются с\\xa0нехваткой пищи и\\xa0уменьшаются, то\\xa0на\\xa0востоке континента сокращение площади морского льда повышает успех их\\xa0размножения. В\\xa0результате общая численность вида остается относительно стабильной. Что ждет его в\\xa0более отдаленном будущем, сказать пока трудно.Каких динозавров находят в Якутии и на Аляске и как им жилось'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloaded_urls[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-rehabilitation",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
